# Sign Language Digit Classifier â€“ CNN from Scratch (NumPy)
This project demonstrates a complete handcrafted **Convolutional Neural Network (CNN)** built **from scratch using only NumPy**, designed to classify **sign language digits (0â€“5)** from RGB images (64Ã—64Ã—3).  
The implementation covers the full deep learning pipeline: **forward pass**, **backward pass**, **training**, **inference**, and **evaluation** â€” without using any high-level frameworks like TensorFlow or PyTorch.


<h3 align="center">Convolutional Neural Network Built From Scratch Using Just NumPy</h3>
<p align="center">
  <img src="images/Convolution_schematic.gif" alt="Convolution Operation" width="700"/>
</p>

> A perfect educational project to show deep understanding of CNN internals and backpropagation!
> Ideal for anyone who wants to master the fundamentals of deep learning from the ground up.

---

## ğŸ§  Model Architecture

```text
Input (64Ã—64Ã—3 RGB Image)
  â†“
Conv2D Layer â€” 8 Filters, 5Ã—5 Kernel, Stride=1, Padding=2
  â†“
ReLU Activation
  â†“
Max Pooling â€” Window=8Ã—8, Stride=8 (Max)
  â†“
Conv2D Layer â€” 16 Filters, 5Ã—5 Kernel, Stride=1, Padding=2
  â†“
ReLU Activation
  â†“
Max Pooling â€” Window=4Ã—4, Stride=4 (Max)
  â†“
Flatten
  â†“
Fully Connected (Dense) â€” 6 Units (One for Each Class)
  â†“
Softmax â€” Multi-class Probability Output

```
### Layer Pipeline (Summary)

`Input` â†’ `Conv2D` â†’ `ReLU` â†’ `MaxPool` â†’ `Conv2D` â†’ `ReLU` â†’ `MaxPool` â†’ `Flatten` â†’ `Dense` â†’ `Softmax`


**Implemented Layers from Scratch**
- 2D Convolution: Custom implementation for feature extraction.  
- ReLU Activation: Non-linear activation function.  
- Max Pooling: Downsampling operation.  
- Dense (Fully Connected) Layer: For classification.  
- Softmax + Cross-Entropy Loss: Output activation and loss function.  
- Complete Backpropagation Logic: Manual gradient calculation for all layers using the Chain Rule  

---

## Results & Training Visualization
<h3 align="center">Forward & Backward Flow</h3> <p align="center"> <img src="images/train_info.png" alt="Forward and Backward Shape Flow" width="700"/> </p> <h3 align="center">Loss Curve Over Epochs</h3> <p align="center"> <img src="images/loss_epoch.png" alt="Loss Curve" width="800"/> </p>

### Experiment Notes:
- Trained on a small subset of sign language digits (0â€“5)
- Visual feedback (shapes, gradients) printed during training
- Clean loss convergence over epochs
- Helps internalize CNN data flow and shape transformations

---

## Project Structure
```bash
cnn-from-scratch-sign-digits/
â”‚
â”œâ”€â”€ notebook.ipynb # Full project code and documentation
â”œâ”€â”€ utils.py # Helper functions
â”œâ”€â”€ datasets/ # Sign language digit images (0â€“5)
â”œâ”€â”€ images/ 
â”‚ â”œâ”€â”€ Convolution_schematic.gif
â”‚ â”œâ”€â”€ loss_epoch.png
â”‚ â””â”€â”€ train_info.png
â””â”€â”€ README.md # You're reading it!
```
---


---

## How to Run

1. Clone the repository:
   ```bash
   git clone https://github.com/nabeelshan78/cnn-from-scratch-sign-digits.git
   cd cnn-from-scratch-sign-digits
2. Open the Jupyter notebook:
   Run the cells to:
    - Load data
    - Initialize parameters
    - Train the CNN
    - Visualize loss and predictions
---

## Key Concepts Mastered
- How convolutional filters detect spatial patterns
- The mathematics of backpropagation through CNNs
- Implementation of gradient descent manually
- Understanding data shapes at each layer
- No use of TensorFlow, Keras, or PyTorch - just NumPy

---

## ğŸ‘¨â€ğŸ’» Author

**Nabeel Shan**  
Software Engineering Student - NUST Islamabad  
Aspiring AI Researcher | AI/ML Enthusiast  
[LinkedIn](https://www.linkedin.com/in/nabeelshan) â€¢ [GitHub](https://github.com/nabeelshan78)  
- Currently focused on mastering CNNs, YOLO, and ResNet architectures.
- Mastering Deep Learning architectures through hands-on work
- Looking to collaborate on AI/ML projects or research opportunities

---

## â­ Star the Repo

If you found this helpful, please consider **starring** ğŸŒŸ the repository - it helps others discover this resource and motivates continued open-source contributions.

---
